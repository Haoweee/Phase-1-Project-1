{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aviation Risk Analysis Project\n",
    "\n",
    "Authors: Brian Woo, Evan Rosenbaum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This project involves data cleaning, imputation, analysis, and visualization to generate insights for a business stakeholder. The goal is to determine the lowest risk aircraft for a company looking to expand into the aviation industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Corporate Stakeholder\n",
    "\n",
    "#### Diversification into the Aviation Industry\n",
    "\n",
    "##### Goals\n",
    "\n",
    "- Our client is looking to diversify their business by venturing into the aviation industry. In doing so, they are looking for new growth opportunities in an industry that has lagged behind other industries in their adoption of technology. \n",
    "\n",
    "#### Priorities\n",
    "\n",
    "##### Safety\n",
    "- Safety is the foremost concern for our client. They are looking for models with impeccable safety records. Further, they a preference for manufacturers with a proven track record of producing safe and reliable aircraft. \n",
    "\n",
    "##### Durability\n",
    "- Our client is looking for an aircraft that has a long operational life. They want to ensure that their investment pays off and that their aircraft can withstand the wear and tear they put on it. \n",
    "\n",
    "##### Lasting Value\n",
    "- Our client wants to be sure that the aircraft they purchase will not be outdated soon after their purchase. Further, they would prefer for their aircraft to be able to meet the current demands and potential future demands of the industry. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source of Data\n",
    "\n",
    "The dataset used for this project is from the National Transportation Safety Board (NTSB) and includes aviation accident data from 1962 to 2023. This dataset covers civil aviation accidents and selected incidents in the United States and international waters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from itertools import combinations\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data_files/AviationData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7153a4da7d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Open the file in read mode and read lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maviation_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data_files/AviationData.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstate_codes_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data_files/USState_Codes.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data_files/AviationData.csv'"
     ]
    }
   ],
   "source": [
    "# Open the file in read mode and read lines\n",
    "\n",
    "aviation_df = pd.read_csv('./data_files/AviationData.csv', encoding='latin-1')\n",
    "\n",
    "state_codes_df = pd.read_csv('./data_files/USState_Codes.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changing the naming convention of columns\n",
    "aviation_df.columns = aviation_df.columns.str.lower().str.replace('.', '_')\n",
    "aviation_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply lambda function to remove whitespace from every element in the DataFrame\n",
    "aviation_df = aviation_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops duplicate rows\n",
    "aviation_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aviation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aviation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aviation_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent of missing values in each column\n",
    "aviation_df.isna().sum() * 100 / len(aviation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique and missing values\n",
    "unique_missing_vals = {}\n",
    "for i in aviation_df.columns:\n",
    "    unique_missing_vals[i] = len(aviation_df[i].unique())\n",
    "\n",
    "unique_values= pd.DataFrame(list(unique_missing_vals.items()), columns = ['Column', 'unique_val'])\n",
    "unique_values[\"missing_values\"] = aviation_df.isna().sum().values\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aviation_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are large outlier inside of all of the injury metrics. However, these outliers are important and give us valuable information about the riskiness of the aircraft.\n",
    "\n",
    "- We should not remove these outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aviation_df.mode().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_info(dataframe, column):\n",
    "    \"\"\"\n",
    "    Provides a view into the row information provided in each column\n",
    "    -\n",
    "    Input:\n",
    "    dataframe : Pandas DataFrame\n",
    "    columns_list: list \n",
    "    -\n",
    "    Output:\n",
    "        Prints:\n",
    "            - A preview of the first 5 values in the column.\n",
    "            - Value counts of the column.\n",
    "            - The percentage of missing values in the column.\n",
    "    \"\"\"\n",
    "    preview = dataframe[column].head()\n",
    "    value_counts = dataframe[column].value_counts()\n",
    "    percent_missing = dataframe[column].isna().sum() * 100 / len(dataframe)\n",
    "    \n",
    "    print(\"Preview of the first 5 rows in the column:\")\n",
    "    print(preview)\n",
    "    print(\"\\nValue counts of the column:\")\n",
    "    print(value_counts)\n",
    "    print(\"\\nPercentage of missing values in the column:\")\n",
    "    print(f\"{percent_missing:.2f}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following columns, we are normalizing the casing to account of duplicated entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns\n",
    "columns_to_lowercase = [\n",
    "    'investigation_type',\n",
    "    'injury_severity',\n",
    "    'aircraft_damage',\n",
    "    'aircraft_category',\n",
    "    'make',\n",
    "    'amateur_built',\n",
    "    'engine_type',\n",
    "    'purpose_of_flight',\n",
    "    'broad_phase_of_flight' \n",
    "]\n",
    "\n",
    "# Convert the columns to lowercase\n",
    "for column in columns_to_lowercase:\n",
    "    aviation_df[column] = aviation_df[column].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### location and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the row entries for the column\n",
    "column_info(aviation_df,'location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "aviation_df['location'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row entry review\n",
    "\n",
    "# Copy the DataFrame so no data is lost\n",
    "aviation_df_copy = aviation_df.copy()\n",
    "\n",
    "# Fill NaN values with a blank string\n",
    "aviation_df_copy['location'].fillna('', inplace=True)\n",
    "\n",
    "# Apply the filter\n",
    "aviation_df_copy[aviation_df_copy['location'].str.contains('NEAR')]['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show if there is a country listed for location values that are NaNs\n",
    "aviation_df['location'][aviation_df['country'] != 'United States'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "The location column while providing more detail than the country file has some issues.\n",
    "\n",
    "First is that not every entry has an accurate city location.\n",
    "\n",
    "Second is that for foreign countries, there are multiple comma delimters indentifying the city. Additionally, the country is listed inside of the location.\n",
    "\n",
    "**Examples**\n",
    "\n",
    "- Los Mochis, Sinaloa, Mexico\n",
    "- Ledbury, Herefordshire, United Kingdom\n",
    "- Panama City, Panama\n",
    "- Ji'an City Jiangxi Province, China\n",
    "\n",
    "**Recommendation**\n",
    "\n",
    "- Filter the data set so that we only have US flights.\n",
    "- Create a state category so we can reliably use the consistent information for location.\n",
    "- Drop the country and location columns. \n",
    "\n",
    "**Action**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for only the rows the country is the United States\n",
    "aviation_df = aviation_df[aviation_df['country'] == 'United States']\n",
    "\n",
    "# Drop NaN values from location\n",
    "aviation_df.dropna(subset=['location'], inplace=True)\n",
    "\n",
    "# Create a new column 'state' that holds the state information from the location column\n",
    "aviation_df['state'] = aviation_df['location'].apply(lambda x: x.split(',')[-1].strip())\n",
    "\n",
    "# Drop the 'location' column\n",
    "aviation_df.drop(columns=['location'], inplace=True)\n",
    "\n",
    "# Drop the 'country' column\n",
    "aviation_df.drop(columns=['country'], inplace=True)\n",
    "\n",
    "# Merge the csv DataFrames on the 'state' column in aviation_df and 'Abbreviation' column in state_codes_df\n",
    "aviation_df = pd.merge(aviation_df, state_codes_df, left_on='state', right_on='Abbreviation', how='inner')\n",
    "\n",
    "# Drop the 'Abbreviation' column as it's no longer needed\n",
    "aviation_df.drop(columns=['Abbreviation'], inplace=True)\n",
    "\n",
    "# Drop the 'Abbreviation' column as it's no longer needed\n",
    "aviation_df.drop(columns=['US_State'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### investigation_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the row entries for the column\n",
    "column_info(aviation_df,'investigation_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "Events are classified as either being accidents or incidents. \n",
    "\n",
    "According to the Code of Federal Regulations, \"an accident is defined as an occurrence associated with the operation of an aircraft which takes place between the time any person boards the aircraft with the intention of flight and all such persons have disembarked, and in which any person suffers death or serious injury, or in which the aircraft receives substantial damage. For purposes of this part, the definition of “aircraft accident” includes “unmanned aircraft accident,” as defined herein.\"\n",
    "\n",
    "An incident is defined as \"an occurrence other than an accident, associated with the operation of an aircraft, which affects or could affect the safety of operations.\"\n",
    "\n",
    "https://www.ecfr.gov/current/title-49/subtitle-B/chapter-VIII/part-830/subpart-A/section-830.2\n",
    "\n",
    "**Recommendation**\n",
    "\n",
    "Narrow our search to only include records that are labeled as accident. \n",
    "- This would result in about 5% of the total data being dropped.\n",
    "\n",
    "**Action**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the event_id column for only accidents\n",
    "aviation_df = aviation_df[aviation_df['investigation_type'] != 'incident']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis for Columns to Drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns with Unique Identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- event_id\n",
    "    - The event_id serves as a unqiue indentifier for each row entry. These are for reference to search the event on the NTSB aviation accident database.\n",
    "- accident_number\n",
    "    - The accident_number serves as a unqiue indentifier for each row entry. These are for reference to search the event on the NTSB aviation accident database.\n",
    "- registration_number\n",
    "    - It is unclear why there is missing values or duplicated values inside of this column as one would assume that every aircrafts registration number would be unique.\n",
    "    - No documentation on this column could be located to provide further information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns with missing values above 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "These columns contain too much missing data. Additionally, they are not pertinent to the business question. \n",
    "\n",
    "**Specific Column Information**\n",
    "\n",
    "- latitude\n",
    "- longitude\n",
    "- far_description\n",
    "    - The column contains references to the Federal Aviation Regulations (FARs) or similar regulatory categories. The FARs are a set of rules prescribed by the Federal Aviation Administration (FAA) governing all aviation activities in the United States.\n",
    "    - The values are not normalized and contain duplicates.\n",
    "     - Examples:\n",
    "        - Part 91: General Aviation\n",
    "            - Covers general operating and flight rules for all aircraft not governed by other specific parts (e.g., private pilots, corporate flights, etc.).\n",
    "        - PUBU: Public Use\n",
    "             - Refers to aircraft operated by government agencies or other public entities for official purposes.\n",
    "        - https://www.faa.gov/hazmat/air_carriers/operations\n",
    "        - https://www.ecfr.gov/current/title-14\n",
    "- schedule\n",
    "    - No documentation on this column could be located to provide further information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns with insignficant data in reference to business question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "These columns while providing interesting information do not provide pertinent information in relation to the busines question. \n",
    "\n",
    "- airport_code\n",
    "- airport_name\n",
    "- air_carrier\n",
    "- publication_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action to Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns that are not useful for analysis\n",
    "columns_to_drop = [\n",
    "    'event_id',\n",
    "    'accident_number',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'airport_code',\n",
    "    'airport_name',\n",
    "    'registration_number',\n",
    "    'far_description',\n",
    "    'schedule',\n",
    "    'air_carrier',\n",
    "    'publication_date',\n",
    "]\n",
    "\n",
    "aviation_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis for Dropping Row NaN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "We want to ensure there is a make and model for every row element. If there is no make and mode, we cannot give a recommendation to the business. \n",
    "\n",
    "**Action**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values inside of the 'make' column\n",
    "aviation_df.dropna(subset=['make', 'model'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis for Columns to Replace NaN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns with no pre-existing unknown category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these columns, there are no pre-existing unknown or other categories. \n",
    "\n",
    "As such, we are filling the NaN values with an 'unknown' string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_replace_with_unknown = [\n",
    "    'purpose_of_flight',\n",
    "    'report_status',\n",
    "    'aircraft_damage',\n",
    "    'aircraft_category',\n",
    "    'model',\n",
    "    'amateur_built'\n",
    "]\n",
    "\n",
    "aviation_df[columns_to_replace_with_unknown] = aviation_df[columns_to_replace_with_unknown].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns with pre-existing unknown category (UNK, Unknown, Other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find Columns with pre-existing unknown category (UNK, Unknown, Other, None) and replace them with 'unknown'\n",
    "columns_to_replace_with_unknown = [\n",
    "    'investigation_type',\n",
    "    'event_date',\n",
    "    'injury_severity', \n",
    "    'aircraft_damage',\n",
    "    'aircraft_category',\n",
    "    'make',\n",
    "    'model',\n",
    "    'amateur_built',\n",
    "    'engine_type',\n",
    "    'purpose_of_flight',\n",
    "    'weather_condition',\n",
    "    'broad_phase_of_flight',\n",
    "    'report_status'\n",
    "]\n",
    "\n",
    "replace_values = ['unk', 'unknown', 'other', 'none', 'unavailable', np.nan]\n",
    "\n",
    "aviation_df[columns_to_replace_with_unknown] = aviation_df[columns_to_replace_with_unknown].applymap(\n",
    "    lambda x: 'unknown' if isinstance(x, str) and x.lower() in replace_values or pd.isna(x) else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Numerical Column Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total_fatal_injuries, total_serious_injuries, total_minor_injuries and total_uninjured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "The total_fatal_injuries, total_serious_injuries, total_minor_injuries, and total_uninjured columns were replaced with the median values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_columns = [\n",
    "    'total_fatal_injuries', \n",
    "    'total_serious_injuries', \n",
    "    'total_minor_injuries', \n",
    "    'total_uninjured'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with 2 rows and 2 columns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Flatten the axes array for easy indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over each column and plot a histogram\n",
    "for i, column in enumerate(injury_columns):\n",
    "    # Drop NaN values before plotting\n",
    "    data = aviation_df[column].dropna()\n",
    "    \n",
    "    # Plot histogram\n",
    "    axes[i].hist(data, bins=100, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    # Calculate mean and median\n",
    "    mean_val = data.mean()\n",
    "    median_val = data.median()\n",
    "    \n",
    "    # Draw vertical lines for mean and median\n",
    "    axes[i].axvline(mean_val, color='red', linestyle='--', linewidth=1, label=f'Mean: {mean_val:.2f}')\n",
    "    axes[i].axvline(median_val, color='blue', linestyle='-', linewidth=1, label=f'Median: {median_val:.2f}')\n",
    "    \n",
    "    # Set title for each subplot\n",
    "    axes[i].set_title(f'Histogram of {column}')\n",
    "    \n",
    "    # Set labels for x and y axes\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Add legend\n",
    "    axes[i].legend()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "Given the positve skew of each column, we will impute the missing values with the median. \n",
    "\n",
    "**Action**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the missing values with the median\n",
    "aviation_df[injury_columns] = aviation_df[injury_columns].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'total_injuries' column\n",
    "aviation_df['total_injuries'] = aviation_df[\n",
    "    ['total_fatal_injuries', \n",
    "     'total_serious_injuries', \n",
    "     'total_minor_injuries'\n",
    "    ]\n",
    "].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number_of_engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "The number_of_engines had to be done differently because, it would be better to be true to the data, because it is impossible to correlate the number of engines in a plane.\n",
    "\n",
    "Big planes could have 1 engine, while another big plane of the same sizes could have 2 or more engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values for histogram\n",
    "value_counts = aviation_df['number_of_engines'].value_counts().sort_index()\n",
    "\n",
    "# Calculate mean and median\n",
    "mean_num_engines = aviation_df['number_of_engines'].mean()\n",
    "median_num_engines = aviation_df['number_of_engines'].median()\n",
    "\n",
    "# Plot a histogram of the value counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "value_counts.plot(kind='bar')\n",
    "plt.xlabel('Number of Engines')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Number of Engines')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add vertical lines for mean and median\n",
    "plt.axvline(x=mean_num_engines, color='red', linestyle='--', linewidth=1, label=f'Mean: {mean_num_engines:.2f}')\n",
    "plt.axvline(x=median_num_engines, color='blue', linestyle='-', linewidth=1, label=f'Median: {median_num_engines:.2f}')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommendation**\n",
    "\n",
    "Unlike the injury columns, this column should be treated as a categorical column since the number of wheels describing the aircraft. \n",
    "\n",
    "As such, we will convert the column type to object and fill the missing values with an unknown category.\n",
    "\n",
    "**Action**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aviation_df['number_of_engines'] = aviation_df['number_of_engines'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Columns and Cleaning Individual Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 'total_injuries' column\n",
    "aviation_df['total_injuries'] = (\n",
    "    aviation_df['total_fatal_injuries'] +\n",
    "    aviation_df['total_serious_injuries'] +\n",
    "    aviation_df['total_minor_injuries']\n",
    ")\n",
    "\n",
    "# Adding 'year', 'month', and 'day' columns\n",
    "aviation_df['event_date'] = pd.to_datetime(aviation_df['event_date'])\n",
    "aviation_df['year'] = aviation_df['event_date'].dt.year\n",
    "aviation_df['month'] = aviation_df['event_date'].dt.month\n",
    "aviation_df['day'] = aviation_df['event_date'].dt.day\n",
    "\n",
    "aviation_df.drop(columns=['event_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Individual Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### injury_severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the count that follows the description of the injury in the 'injury_severity column'\n",
    "aviation_df['injury_severity'] = aviation_df['injury_severity'].apply(lambda x: x.split('(')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### report_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_info(aviation_df, 'report_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review:**\n",
    "\n",
    "After reviewing the report status for accidents there is a large number of records the mention the pilot as the source of the accident. \n",
    "\n",
    "However, the most common entries in the column are:\n",
    "\n",
    "- Probable Cause : 61754\n",
    "- Foreign : 1999\n",
    "- Factual : 167\n",
    "\n",
    "**Recommendation:**\n",
    "\n",
    "We make a column identifying explicit pilot error by searching for the keyword of pilot. The keyword while general is reflective of pilot error given that each row represents an accident and that when a description is given, it is telling us about the error that occurred that caused the accident. \n",
    "\n",
    "The new column will be a boolean value. \n",
    "\n",
    "Fill the NaN values with 'unknown'\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- \"The pilot’s decision to perform a takeoff from a perpendicular taxiway rather than the airport runway, which led to the airplane striking trees at the end of the departure path.\"\n",
    "\n",
    "- \"The pilot’s failure to maintain airplane control during the landing roll on a snow-covered runway surface.\"\n",
    "\n",
    "- \"The pilot’s failure to retract the flaps during a go-around from a bounced landing, which resulted in a collision with trees then terrain.\"\n",
    "\n",
    "**Action**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'human_error' with True and False labels based on 'investigation_type'\n",
    "aviation_df['human_error'] = aviation_df['investigation_type'].str.contains('pilot', case=False) | aviation_df['investigation_type'].str.contains('instructor', case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the mapping of individual make names to origin names\n",
    "make_origin_mapping = {}\n",
    "\n",
    "# Iterate over each make in aviation_df to extract the origin name\n",
    "for make in aviation_df['make'].unique():\n",
    "    origin_make = make.split()[0]  # Get the origin make ('mcdonnell douglas helicopter' from 'mcdonnell')\n",
    "    make_origin_mapping[make] = origin_make\n",
    "    \n",
    "aviation_df['make'] = aviation_df['make'].map(make_origin_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commerical Jet Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_bar_chart(dataframe, categorical_col, numerical_col, measure, sort_boolean, num_of_values_shown):\n",
    "    # Calculate numerical measure for each categorical column\n",
    "    num_by_cat = dataframe.groupby(categorical_col)[numerical_col].agg(measure)\n",
    "    \n",
    "    #Sort the data\n",
    "    num_by_cat = num_by_cat.sort_values(ascending=sort_boolean).head(num_of_values_shown)\n",
    "    \n",
    "    # Plot the bar chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    num_by_cat.plot(kind='bar', color='skyblue')\n",
    "    plt.title(f'{numerical_col} by {categorical_col}')\n",
    "    plt.xlabel(f'{categorical_col}')\n",
    "    plt.ylabel(f'{numerical_col}')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_comparison_bar_chart(aviation_df, 'purpose_of_flight', 'total_injuries', 'sum', False, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our stakeholder wants to see whether to get into the Commercial or Private airline industry based primarily on the safety of the aircraft. \n",
    "\n",
    "At present, the data set does not have a classification for Commercial Flights inside of the 'purpose_of_flight' column. \n",
    "\n",
    "Commercial Travel Planes primarily use Turbo Fan engines however the data set includes duplicate plane models inside of the Turbo Jet engine classification. To account for this, we are going to include both engine types and manually review the models to ensure only commercial planes are included in the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specific engine types and select relevant columns\n",
    "filtered_df = aviation_df[\n",
    "    aviation_df['engine_type'].isin(['turbo fan', 'turbo jet'])\n",
    "][['make', 'model', 'engine_type', 'purpose_of_flight']]\n",
    "\n",
    "# Filter the DataFrame to exclude erroneous plane addition\n",
    "final_airbus_df = filtered_df[(filtered_df['model'] != 'F4-6')]\n",
    "\n",
    "# Count occurrences and reset the index\n",
    "value_counts_df = final_airbus_df.value_counts().reset_index()\n",
    "\n",
    "# Filter for instances containing 'airbus'\n",
    "airbus_commerical_planes = value_counts_df[value_counts_df['make'].str.contains('airbus', case=False)]\n",
    "\n",
    "# Get unique models\n",
    "unique_airbus_commerical_planes = airbus_commerical_planes['model'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Airbus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus_replace_dict = {}\n",
    "\n",
    "for plane in unique_airbus_commerical_planes:\n",
    "    if not plane[0].isalpha(): \n",
    "        # If the first character is not a letter, prefix the plane name with 'A' and take the first three characters of the original name\n",
    "        airbus_replace_dict[plane] = 'A' + plane[:3]\n",
    "    elif plane[1] == '-': \n",
    "        # If the second character is a hyphen, remove the hyphen and take the first four characters of the modified name\n",
    "        airbus_replace_dict[plane] = plane.replace('-', '')[:4]\n",
    "    else:\n",
    "        # Take the first four characters of the plane name\n",
    "        airbus_replace_dict[plane] = plane[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to exclude erroneous plane addition\n",
    "final_airbus_df = filtered_df[(filtered_df['model'] != 'DC-10')]\n",
    "\n",
    "# Count occurrences and reset the index\n",
    "value_counts_df = filtered_df.value_counts().reset_index()\n",
    "\n",
    "# Filter for instances containing 'boeing'\n",
    "unique_boeing_commercial_planes = value_counts_df[value_counts_df['make'].str.contains('boeing', case=False)]\n",
    "\n",
    "# Get unique models\n",
    "unique_boeing_commercial_planes = unique_boeing_commercial_planes['model'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boeing_replace_dict = {}\n",
    "for plane in unique_boeing_commercial_planes:\n",
    "    if plane[1] == '-':\n",
    "        # If the plane starts with 'B' and contains '-', like 'B737-300', take the part after 'B' and before the '-'\n",
    "        boeing_replace_dict[plane] = plane.replace('-', '')[1:4]\n",
    "    elif \"BOEING\" in plane:\n",
    "        # If the plane contains 'BOEING', like 'BOEING 777-236',remove 'BOEING', strip leading/trailing whitespace,\n",
    "        # and extract the first three digits from the remaining string\n",
    "        boeing_replace_dict[plane] = plane.replace('BOEING', '')[1:4]\n",
    "    elif \"MD\" in plane or \"DC\" in plane:\n",
    "        # If the plane contains 'MD' or 'DC', like 'MD-11' or 'DC-10', take the first five characters of the plane\n",
    "        boeing_replace_dict[plane] = plane[:5]\n",
    "    elif plane[0].isalpha():\n",
    "        # If the plane starts with an alpha character, take characters from index 1 to 4\n",
    "        boeing_replace_dict[plane] = plane[1:4]\n",
    "    else:\n",
    "        # Take the first three characters\n",
    "        boeing_replace_dict[plane] = plane[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### McDonell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mcdonnell douglas planes\n",
    "filter_mcdonnell_planes = aviation_df[\n",
    "    (aviation_df['engine_type'].isin(['turbo fan', 'turbo jet'])) & \n",
    "    (aviation_df['purpose_of_flight'] == 'commercial flight') &\n",
    "    (aviation_df['make'] == 'mcdonnell')\n",
    "]['model'].unique()\n",
    "\n",
    "# remove the rows with model 'RF-4C' and F/A-18C in filter_mcdonnell_planes\n",
    "models_to_remove = ['RF-4C', 'F/A-18C']\n",
    "unique_mcdonnell_commerical_planes = [model for model in filter_mcdonnell_planes if model not in models_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdonnell_replace_dict = {}\n",
    "\n",
    "for plane in unique_mcdonnell_commerical_planes:\n",
    "    # Use regex to split the model\n",
    "    parts = re.split(r'[- ]', plane)\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        # Extract only numeric part from the second segment\n",
    "        numeric_part = ''.join(filter(str.isdigit, parts[1]))\n",
    "        if numeric_part:\n",
    "            if plane == 'DC10-30F':\n",
    "                mcdonnell_replace_dict[plane] = 'DC10'\n",
    "            elif plane == 'DC8-63F':\n",
    "                mcdonnell_replace_dict[plane] = 'DC8'\n",
    "            else:\n",
    "                mcdonnell_replace_dict[plane] = parts[0] + numeric_part\n",
    "        else:\n",
    "            mcdonnell_replace_dict[plane] = parts[0]\n",
    "    else:\n",
    "        \n",
    "        mcdonnell_replace_dict[plane] = plane.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Embraer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the embraer planes\n",
    "unique_embraer_commerical_planes = aviation_df[\n",
    "    (aviation_df['engine_type'].isin(['turbo fan', 'turbo jet'])) & \n",
    "    (aviation_df['purpose_of_flight'] == 'commercial flight') &\n",
    "    (aviation_df['make'] == 'embraer')\n",
    "]['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get the first 6 letters (erj) and numbers in filter_embraer_planes\n",
    "embraer_replace_dict = {}\n",
    "for plane in unique_embraer_commerical_planes:\n",
    "    embraer_replace_dict[plane] = 'ERJ' + ''.join(filter(str.isdigit, plane[:7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fokker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the fokker planes\n",
    "unique_fokker_commercial_planes = aviation_df[\n",
    "    (aviation_df['engine_type'].isin(['turbo fan', 'turbo jet'])) & \n",
    "    (aviation_df['purpose_of_flight'] == 'commercial flight') &\n",
    "    (aviation_df['make'] == 'fokker')\n",
    "]['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only f and get the next full number\n",
    "fokker_replace_dict = {}\n",
    "for plane in unique_fokker_commercial_planes:\n",
    "    # print(plane)\n",
    "    hypen_splitter = plane.split('-')\n",
    "    space_splitter = plane.split(' ')\n",
    "    if not plane[0].isalpha():\n",
    "        fokker_replace_dict[plane] = 'F' + ''.join(filter(str.isdigit, plane[:2]))\n",
    "    elif plane[2] == '-':\n",
    "        value = hypen_splitter[0] + hypen_splitter[1]\n",
    "        fokker_replace_dict[plane] = value.replace('K', '')\n",
    "    elif space_splitter[0] == 'F28':\n",
    "        fokker_replace_dict[plane] = 'F28'\n",
    "    elif plane[1] == '-':\n",
    "        fokker_replace_dict[plane] = space_splitter[0].replace('-', '')\n",
    "    elif plane[1] == '.':\n",
    "        fokker_replace_dict[plane] = space_splitter[0].replace('.', '')\n",
    "    else:\n",
    "        fokker_replace_dict[plane] = plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lockheed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the lockheed planes\n",
    "unique_lockheed_commercial_planes = aviation_df[\n",
    "    (aviation_df['engine_type'].isin(['turbo fan', 'turbo jet'])) & \n",
    "    (aviation_df['purpose_of_flight'] == 'commercial flight') &\n",
    "    (aviation_df['make'] == 'lockheed')\n",
    "]['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lockheed_replace_dict = {}\n",
    "for plane in unique_lockheed_commercial_planes:\n",
    "    hypen_splitter = plane.split('-')\n",
    "    if plane[1] == '-':\n",
    "        lockheed_replace_dict[plane] = hypen_splitter[0] + hypen_splitter[1]\n",
    "    else:\n",
    "        lockheed_replace_dict[plane] = hypen_splitter[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Illyushin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the illyushin planes\n",
    "unique_ilyushin_commercial_plane = aviation_df[\n",
    "    (aviation_df['engine_type'].isin(['turbo fan', 'turbo jet'])) & \n",
    "    (aviation_df['purpose_of_flight'] == 'commercial flight') &\n",
    "    (aviation_df['make'] == 'ilyushin')\n",
    "]['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilyushin_replace_dict = {}\n",
    "unique_ilyushin_commercial_plane[0].replace('-', '')\n",
    "ilyushin_replace_dict[unique_ilyushin_commercial_plane[0]] = unique_ilyushin_commercial_plane[0].replace('-', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply replacement dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_replacement_dictionaries = [\n",
    "    airbus_replace_dict,\n",
    "    boeing_replace_dict,\n",
    "    mcdonnell_replace_dict,\n",
    "    embraer_replace_dict,\n",
    "    fokker_replace_dict,\n",
    "    lockheed_replace_dict,\n",
    "    ilyushin_replace_dict\n",
    "]\n",
    "\n",
    "# Apply the replacements\n",
    "for replace_dict in list_of_replacement_dictionaries:\n",
    "    aviation_df['model'] = aviation_df['model'].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill 'purpose_of_flight' with commercial flight classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makes_to_include = [\n",
    "    'boeing', \n",
    "    'airbus', \n",
    "    'embraer', \n",
    "    'mcdonnell', \n",
    "    'lockheed', \n",
    "    'douglas', \n",
    "    'fokker', \n",
    "    'ilyushin'\n",
    "]\n",
    "\n",
    "aviation_df.loc[\n",
    "    (\n",
    "        ((aviation_df['engine_type'] == 'turbo fan') | (aviation_df['engine_type'] == 'turbo jet')) &\n",
    "        (aviation_df['purpose_of_flight'] == 'unknown') &\n",
    "        ((aviation_df['amateur_built'] == 'no') | (aviation_df['amateur_built'] == 'unknown')) &\n",
    "        (aviation_df['make'].isin(makes_to_include))\n",
    "    ),\n",
    "    'purpose_of_flight'\n",
    "] = 'commercial flight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make and model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'make_model' column\n",
    "aviation_df['make_model'] = aviation_df['make'] + ' ' + aviation_df['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aviation_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Question 1: Which area of the avaiation industry should they get into?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our stakeholders first priority being safety, we want to determine which portion of the industry either commerical flights or private flights is safer. \n",
    "\n",
    "To measure safety, we are using the total number of injuries (fatal, serious, and minor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_comparison_bar_chart(aviation_df, 'purpose_of_flight', 'total_injuries', 'sum', False, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "Overwhelmingly, the largest cause of injury when onboard an aircraft is while flying for personal reasons. This could be due to a multitude of reasons, cheif among them is flight hours.\n",
    "\n",
    "Given the data, the hourly requirement should be increased to limit the injuries caused by personal flights. \n",
    "\n",
    "\"A person applying for a private pilot certificate in airplanes, helicopters, and gyro-planes must log at least 40 hours of flight time, of which at least 20 hours are flight training from an authorized instructor and 10 hours of solo flight training in the appropriate areas of operation; three hours of cross country; three hours at night, three hours of instrument time; and other requirements specific to the category and class rating sought.\n",
    "\n",
    "Private pilots in gliders and lighter-than-air aircraft must have logged from an authorized instructor a similar number of hours and/ or training flights, which include both cross country and solo according to category and class rating sought. Though the regulations require a minimum of 40 hours flight time, in the U. S. the average number of hours for persons without a hearing impairment completing the private pilot certification requirements is approximately 75 hours.\"\n",
    "\n",
    "Importantly, commercial flights are slightly less risky than business flights. If we include executive/corporate flight purposes in with business flights, we see that commercial flights are the safer option between private or commercial flights. \n",
    "\n",
    "- https://www.faa.gov/faq/what-are-hourly-requirements-becoming-pilot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**\n",
    "\n",
    "Given that commercial flights have a higher degree of safety (fewer total injuries) than business/executive/corporate flights we suggest to our stakeholder that pursue commercial flights rather than private flights. \n",
    "\n",
    "As such, we will trim our data set to view only commercial flights so that we can provide targeted insights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commercial_flights_df = aviation_df[(aviation_df['purpose_of_flight'] == 'commercial flight')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commercial_flights_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_iqr(dataframe, column):\n",
    "    \"\"\"\n",
    "    Find the outliers in the column using the IQR method\n",
    "    -\n",
    "    Input: \n",
    "        dataframe: Pandas DataFrame\n",
    "        column: str\n",
    "    -\n",
    "    Output:\n",
    "        Prints:\n",
    "            - The number of outliers in the column.\n",
    "            - The percentage of outliers in the column.\n",
    "    \"\"\"\n",
    "    q1 = dataframe[column].quantile(0.25)\n",
    "    q3 = dataframe[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    "    \n",
    "    outliers = dataframe[(dataframe[column] < lower_bound) | (dataframe[column] > upper_bound)]\n",
    "    percent_outliers = len(outliers) * 100 / len(dataframe)\n",
    "    \n",
    "    print(f\"Number of outliers: {len(outliers)}\")\n",
    "    print(f\"Percentage of outliers: {percent_outliers:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    'total_fatal_injuries',\n",
    "    'total_serious_injuries',\n",
    "    'total_minor_injuries',\n",
    "    'total_uninjured',\n",
    "    'total_injuries'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for box plots\n",
    "fig, axes = plt.subplots(nrows=len(numerical_columns), ncols=1, figsize=(10, 6 * len(numerical_columns)))\n",
    "\n",
    "# Plot each numerical column in a separate subplot\n",
    "for ax, column in zip(axes, numerical_columns):\n",
    "    sns.boxplot(data=commercial_flights_df, x=column, ax=ax)\n",
    "    ax.set_title(f'Box Plot for {column}')\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the number/percentage of outliers\n",
    "\n",
    "for column in numerical_columns:\n",
    "    print('\\n', column)\n",
    "    find_outliers_iqr(commercial_flights_df, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box and whisker plots above show a line rather than a rectangle for the IQR because the range of the IQR is between 0 and 1. On the graph, when comparing the IQR to the outliers that exist, the range of the outliers far outsizes the range of the IQR.\n",
    "\n",
    "**Handling Outliers**\n",
    "\n",
    "Even though the outliers skew the columns, we will keep all of the outliers that are in all of the numerical columns because the outliers are relevant data points that provide useful information for each column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Columns Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commercial_flights_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use correlation matrices and scatter plots to understand relationships between numerical variables\n",
    "correlation_matrix = commercial_flights_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.matshow(correlation_matrix, cmap='coolwarm', fignum=1)\n",
    "plt.colorbar(label='correlation coefficient')\n",
    "plt.xticks(range(len(correlation_matrix.columns)), correlation_matrix.columns, rotation='vertical')\n",
    "plt.yticks(range(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(dataframe, columns):\n",
    "    \"\"\"\n",
    "    Create scatter plots for numerical columns.\n",
    "    -\n",
    "    Input:\n",
    "        dataframe: Pandas DataFrame\n",
    "        columns: list of column names (strings)\n",
    "    -\n",
    "    Output:\n",
    "        Displays scatter plots for each column pair\n",
    "    \"\"\"\n",
    "    for i in range(len(columns)):\n",
    "        for j in range(i+1, len(columns)):\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.scatter(dataframe[columns[i]], dataframe[columns[j]], alpha=0.5)\n",
    "            plt.xlabel(columns[i])\n",
    "            plt.ylabel(columns[j])\n",
    "            plt.title(f'{columns[i]} vs {columns[j]}')\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical columns to compare\n",
    "numerical_columns = ['total_fatal_injuries', 'total_serious_injuries', 'total_minor_injuries', 'total_uninjured']\n",
    "\n",
    "# Call the function with the dataframe and the list of columns\n",
    "scatter_plot(commercial_flights_df, numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Columns Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_squared_test(dataframe, column1, column2):\n",
    "    \"\"\"\n",
    "    Perform a chi-squared test for independence between two categorical variables.\n",
    "    \n",
    "    Input:\n",
    "        dataframe: Pandas DataFrame\n",
    "        column1: str\n",
    "        column2: str\n",
    "        \n",
    "    Output:\n",
    "        Returns chi-squared test statistic, p-value, and degrees of freedom.\n",
    "    \"\"\"\n",
    "    contingency_table = pd.crosstab(dataframe[column1], dataframe[column2])\n",
    "    chi2, p, dof, _ = chi2_contingency(contingency_table)\n",
    "    return chi2, p, dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlating_columns(dataframe, columns_to_compare, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Find the most correlating columns using the chi-squared test.\n",
    "    \n",
    "    Input:\n",
    "        dataframe: Pandas DataFrame\n",
    "        columns_to_compare: list of str, specific columns to include in the comparison\n",
    "        alpha: float, significance level\n",
    "        \n",
    "    Output:\n",
    "        DataFrame with pairs of columns and their chi-squared test results.\n",
    "    \"\"\"\n",
    "    # Replace placeholders with NaNs\n",
    "    dataframe.replace(['unknown', 'N/A', 'na', '', ' '], pd.NA, inplace=True)\n",
    "    \n",
    "    # Drop rows with NaNs in the specified columns\n",
    "    dataframe = dataframe[columns_to_compare].dropna()\n",
    "    \n",
    "    # Generate pairs of specified columns\n",
    "    column_pairs = list(combinations(columns_to_compare, 2))\n",
    "    \n",
    "    # Perform chi-squared test for each pair\n",
    "    results = []\n",
    "    for col1, col2 in column_pairs:\n",
    "        chi2, p, dof = chi_squared_test(dataframe, col1, col2)\n",
    "        # Append results if the p-value is less than or equal to the alpha level\n",
    "        if p <= alpha:\n",
    "            results.append((col1, col2, chi2, p, dof))\n",
    "    \n",
    "    # Create a DataFrame to store results\n",
    "    results_df = pd.DataFrame(results, columns=['Column 1', 'Column 2', 'Chi-squared', 'P-value', 'Degrees of Freedom'])\n",
    "    \n",
    "    # Sort by P-value first and then by Chi-squared test statistic\n",
    "    results_df.sort_values(by=['P-value', 'Chi-squared'], ascending=[True, False], inplace=True)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_compare = ['total_injuries', \n",
    "                      'aircraft_damage',\n",
    "                      'weather_condition', \n",
    "                      'broad_phase_of_flight', \n",
    "                      'make_model', \n",
    "                      'state', \n",
    "                      'year',\n",
    "                      'month'\n",
    "]\n",
    "chi_square_df = commercial_flights_df[columns_to_compare].copy()\n",
    "\n",
    "correlating_columns = find_correlating_columns(chi_square_df, columns_to_compare, alpha=0.01)\n",
    "correlating_columns.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Above are the 10 most relevant data to compare based on p-value and the chi-squared tests.\n",
    "- The p-value represents the probability of observing the test results.\n",
    "    - Ranges from 0-1\n",
    "    - Closer to 0 indicates a strong connection\n",
    "    - Closer to 1 indicates a weaker connection\n",
    "\n",
    "- The Chi-squared stat measures the difference between the actual data and the expected data\n",
    "    - Higher stat indicates a stronger connection\n",
    "    - Lower stat indicates a weaker connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which make and model is most dangerous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 'amateur_built' planes so we only see non-amateur or unknown planes\n",
    "create_comparison_bar_chart(commercial_flights_df, 'make', 'total_injuries', 'sum', False, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'make_model' by combining 'make' and 'model' columns\n",
    "create_comparison_bar_chart(commercial_flights_df, 'make_model', 'total_injuries', 'sum', False, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which state has the most accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_comparison_bar_chart(commercial_flights_df, 'state', 'total_injuries', 'sum', False, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which weather pattern is most dangerous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_comparison_bar_chart(commercial_flights_df, 'weather_condition', 'total_injuries', 'sum', False, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which phase of flight of most dangerous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_comparison_bar_chart(commercial_flights_df, 'broad_phase_of_flight', 'total_injuries', 'sum', False, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which engine type is most dangerous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_comparison_bar_chart(commercial_flights_df, 'engine_type', 'total_injuries', 'sum', False, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the number of engines the aircraft has mitigate the damage done to the aircraft?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'aircraft_damage' and 'number_of_engines' and count the frequency of each combination\n",
    "grouped_data = commercial_flights_df.groupby(['aircraft_damage', 'number_of_engines']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot the grouped bar chart\n",
    "grouped_data.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Comparison of Aircraft Damage by Number of Engines')\n",
    "plt.xlabel('Aircraft Damage')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Number of Engines')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Avaiation Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame to show pertinent values\n",
    "yearly_injuries = commercial_flights_df.groupby('year')['total_injuries'].sum()\n",
    "\n",
    "# Plot the results\n",
    "yearly_injuries.plot(kind='line', figsize=(10, 6))\n",
    "plt.title('Total Injuries by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Injuries')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of accidents and fatal injuries per year\n",
    "accidents_per_year = commercial_flights_df.groupby('year').size()\n",
    "fatal_injuries_per_year = aviation_df.groupby('year')['total_fatal_injuries'].sum()\n",
    "\n",
    "# Calculate the fatality rate per year\n",
    "fatality_rate_per_year = fatal_injuries_per_year / accidents_per_year\n",
    "\n",
    "# Plot the fatality rate over the years\n",
    "plt.figure(figsize=(10, 6))\n",
    "fatality_rate_per_year.plot(kind='line', color='red', marker='o')\n",
    "plt.title('Fatality Rate per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Fatality Rate')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of fatal injuries per month\n",
    "fatal_injuries_per_month = commercial_flights_df.groupby('month')['total_fatal_injuries'].sum()\n",
    "\n",
    "# Plot the count of fatal injuries for each month\n",
    "plt.figure(figsize=(10, 6))\n",
    "fatal_injuries_per_month.plot(kind='bar', color='blue')\n",
    "plt.title('Count of Fatal Injuries per Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count of Fatal Injuries')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commerical Aircraft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do certain commerical aircraft perform better in different weather conditions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'make_model' and 'weather_condition', count values, convert to single index DataFrame\n",
    "weather_counts = commercial_flights_df.groupby(['make_model', 'weather_condition']).size().unstack()\n",
    "\n",
    "# Sum the counts of the columns ('make_model' by 'weather_condition')\n",
    "weather_counts_total = weather_counts.sum(axis=1)\n",
    "\n",
    "# Sort the total counts in descending order\n",
    "weather_counts_total_sorted = weather_counts_total.sort_values(ascending=False)\n",
    "\n",
    "# Sorts the weather_counts df by using the indexes of the series weather_counts_total_sorted \n",
    "weather_counts_sorted = weather_counts.loc[weather_counts_total_sorted.index]\n",
    "\n",
    "# Plotting\n",
    "weather_counts_sorted.plot(kind='bar', stacked=True, figsize=(12, 8))\n",
    "plt.title('Counts of Incidents by Aircraft Model and Weather Condition')\n",
    "plt.xlabel('Aircraft Model')\n",
    "plt.ylabel('Count of Accidents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Weather Condition')\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "- VMC\n",
    "    - \"...is an aviation flight category in which visual flight rules (VFR) flight is permitted—that is, conditions in which pilots have sufficient visibility to fly the aircraft maintaining visual separation from terrain and other aircraft. They are the opposite of instrument meteorological conditions (IMC).\"\n",
    "    - https://en.wikipedia.org/wiki/Visual_meteorological_conditions\n",
    "        \n",
    "- IMC\n",
    "     - \"...are weather conditions that require pilots to fly primarily by reference to flight instruments, and therefore under instrument flight rules (IFR), as opposed to flying by outside visual references under visual flight rules (VFR). Typically, this means flying in cloud or poor weather, where little or nothing can be seen or recognised when looking out of the window.\"\n",
    "     - https://en.wikipedia.org/wiki/Instrument_meteorological_conditions\n",
    "\n",
    "The data here shows that the majority of accidents occurred while there was sufficient visibility to fly the aircraft. It is worth looking into the data further to see if there is a way to determine if human error could have resulted in an accident in either IMC or VMC weather conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are certain commerical aircraft more susceptible to human error? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'make_model' and 'human_error', count values, convert to single index DataFrame\n",
    "human_error_counts = commercial_flights_df.groupby(['make_model', 'human_error']).size().unstack()\n",
    "\n",
    "# Sum the counts of the columns ('make_model' by 'human_error')\n",
    "human_error_counts_total = human_error_counts.sum(axis=1)\n",
    "\n",
    "# Sort the total counts in descending order\n",
    "human_error_counts_total_sorted = human_error_counts_total.sort_values(ascending=False)\n",
    "\n",
    "# Sorts the human_error_counts df by using the indexes of the series human_error_counts_total_sorted \n",
    "human_error_counts_sorted = human_error_counts.loc[human_error_counts_total_sorted.index]\n",
    "\n",
    "# Plotting\n",
    "human_error_counts_sorted.plot(kind='bar', stacked=True, figsize=(12, 4))\n",
    "plt.title('Counts of Accidents by Aircraft Model and Human Error')\n",
    "plt.xlabel('Aircraft Model')\n",
    "plt.ylabel('Count of Accidents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Human Error')\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "Fortunately, there are no accidents in commercial aircrafts that were explicitly the result of human error. It is worth noting that the 'report_staus' column did have ~7% missing values so there is the chance that an accident was the result of human error. \n",
    "\n",
    "Regardless of the weather condition (IMC v VMC), pilots of commercial aircrafts are not the root cause of the accident. \n",
    "\n",
    "For our stakeholder, this is good news as it allows a direct comparison of commercial aircraft as the accidents should all be caused by the aircraft itself and not the crew piloting the aircraft. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are certain commerical aircraft more durable than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'make_model' and 'aircraft_damage', count values, convert to single index DataFrame\n",
    "damage_counts = commercial_flights_df.groupby(['make_model', 'aircraft_damage']).size().unstack()\n",
    "\n",
    "# Sum the counts of the columns ('make_model' by 'weather_condition')\n",
    "damage_counts_total = damage_counts.sum(axis=1)\n",
    "\n",
    "# Sort the total counts in descending order\n",
    "damage_counts_total_sorted = damage_counts_total.sort_values(ascending=False)\n",
    "\n",
    "# Sorts the weather_counts df by using the indexes of the series weather_counts_total_sorted \n",
    "damage_counts_sorted = damage_counts.loc[damage_counts_total_sorted.index]\n",
    "\n",
    "# Plotting\n",
    "damage_counts_sorted.plot(kind='bar', stacked=True, figsize=(12, 8))\n",
    "plt.title('Counts of Incidents by Aircraft Model and Aircraft Damage')\n",
    "plt.xlabel('Aircraft Model')\n",
    "plt.ylabel('Count of Accidents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Aircraft Damage')\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "While there are lot of unknown values, one thing is clear. When commercial aircraft get into accidents, they are rarely destroyed. Most of the time the damage is substantial but not beyond repair. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the safest commerical aircraft?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_comparison_bar_chart(commercial_flights_df, 'make_model', 'total_injuries', 'sum', False, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Your Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "Based on our findings we have concluded that these are the 3 top choices for your commerical airline company:\n",
    "\n",
    "1. **Boeing 787**\n",
    "- Pros:\n",
    "    - Advanced technology and fuel efficiency (8,463 miles).\n",
    "    - High passenger comfort with modern amenities.\n",
    "    - No fatalities or hull losses reported.\n",
    "\n",
    "- Cons:\n",
    "    - Early operational issues with lithium-ion batteries.\n",
    "    - Significant quality control issues and production slowdowns.\n",
    "\n",
    "Verdict: Despite initial issues, the Boeing 787 is a reliable and modern aircraft suitable for long-haul flights, with a strong safety record post-battery redesign.\n",
    "\n",
    "2. **Airbus A321**\n",
    "\n",
    "- Pros:\n",
    "    - Common type rating with other A320-family variants, reducing pilot training costs.\n",
    "    - Still in production, ensuring parts availability and support.\n",
    "    - Suitable for short to medium-haul routes (~4,000 miles).\n",
    "\n",
    "- Cons:\n",
    "    - Limited range operations, designed for short to medium flights.\n",
    "\n",
    "Verdict: The Airbus A321 is a versatile, cost-effective option for medium-haul routes, benefiting from commonality with other A320-family aircraft.\n",
    "\n",
    "3. **Airbus A330**\n",
    "\n",
    "- Pros:\n",
    "    - Extensive service history with more than 65 million flight hours.\n",
    "    - Still in production, ensuring continued support and parts availability.\n",
    "    - Well-suited for long flying ranges (~8,300 miles)\n",
    "\n",
    "- Cons:\n",
    "    - Less fuel efficient, which can result in high operational costs.\n",
    "    - Older model plane, less advanced technology and lower overall efficiency.\n",
    "    - Poor engine performance, which can decrease fuel efficiency and cause cabin vibrations.\n",
    "\n",
    "Verdict: The Airbus A330 is a proven, reliable aircraft for medium to long-haul routes with a strong operational track record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
